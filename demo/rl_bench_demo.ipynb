{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb0b04-3421-4021-9220-103904900132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from __future__ import absolute_import\n",
    "# from __future__ import print_function\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch.optim as optim\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "import relaxit\n",
    "\n",
    "from relaxit.rl_benchmarks.algorithms.reinforce import REINFORCE\n",
    "from relaxit.rl_benchmarks.algorithms.a2c import A2C\n",
    "from relaxit.rl_benchmarks.algorithms.relax import RELAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0417d64-a8ec-499a-b6fa-84441b02934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot formatting\n",
    "plt.rcParams['font.family'] = 'DejaVu Serif'\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.markersize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "plt.rcParams['legend.fontsize'] = 24\n",
    "plt.rcParams['axes.titlesize'] = 36\n",
    "plt.rcParams['axes.labelsize'] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c184b4-1a95-4879-bd4c-053260a8eb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb56db-a26b-4946-b031-a158845f44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_tilde_z_samples_params(logits):  # logits = log P(b | theta)\n",
    "    u = torch.rand_like(logits, device=logits.device)\n",
    "    v = torch.rand_like(logits, device=logits.device)\n",
    "    z = logits - torch.log(-torch.log(u))\n",
    "    samples = torch.argmax(z)\n",
    "\n",
    "    tilde_z = -torch.log(-torch.log(v)/torch.exp(logits) -\n",
    "                         torch.log(v)[samples])\n",
    "    tilde_z[samples] = -torch.log(-torch.log(v))[samples]\n",
    "\n",
    "    return z, tilde_z, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0715330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch.optim as optim\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "\n",
    "\n",
    "def apply_benchmark(algorithm : str = 'REINFORCE', \n",
    "                    env_name = 'CartPole-v1', \n",
    "                    max_steps : int = 256,\n",
    "                    max_episode: int = 100):\n",
    "    LR = 0.002  # Learning rate\n",
    "    SEED = 42  # Random seed for reproducibility\n",
    "    #MAX_EPISODES = 350  # Max number of episodes\n",
    "    LOG_INTERVAL = 10\n",
    "    HIDDEN_SIZE: int = 64\n",
    "\n",
    "    # Init actor-critic agent\n",
    "    if algorithm == 'REINFORCE':\n",
    "        agent = REINFORCE(gym.make(env_name), hidden_size=HIDDEN_SIZE, gamma=.99, max_steps = max_steps, random_seed=SEED)\n",
    "    elif algorithm == 'RELAX':\n",
    "        agent = RELAX(gym.make(env_name), hidden_size = HIDDEN_SIZE, gamma=0.99, max_steps = max_steps, random_seed=SEED)\n",
    "    elif algorithm == 'A2C':\n",
    "        agent = A2C(gym.make(env_name), hidden_size = HIDDEN_SIZE, gamma=0.99, max_steps = max_steps, random_seed=SEED)\n",
    "\n",
    "    # Init optimizers\n",
    "    actor_optim = optim.Adam(agent.actor.parameters(), lr=LR)\n",
    "    if algorithm != 'REINFORCE':\n",
    "        critic_optim = optim.Adam(agent.critic.parameters(), lr=LR)\n",
    "\n",
    "    #\n",
    "    # Train\n",
    "    #\n",
    "\n",
    "    r = []  # Array containing total rewards\n",
    "    avg_r = 0  # Value storing average reward over last 100 episodes\n",
    "\n",
    "    running_reward = 0\n",
    "\n",
    "    ep_rewards = []\n",
    "    running_rewards = []\n",
    "\n",
    "    for i in range(max_episode):\n",
    "        if algorithm == 'REINFORCE':\n",
    "            total_reward = agent.train_one_episode(optimizer=actor_optim)\n",
    "        else:\n",
    "            total_reward = agent.train_one_episode(actor_optimizer=actor_optim, critic_optimizer=critic_optim)\n",
    "\n",
    "        ep_reward = total_reward\n",
    "        if running_reward == 0:\n",
    "            running_reward = ep_reward\n",
    "        running_reward = 0.01 * ep_reward + (1 - 0.01) * running_reward\n",
    "        ep_rewards.append(ep_reward)\n",
    "        running_rewards.append(running_reward)\n",
    "        \n",
    "        if i % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                \"Episode {}\\tLast reward: {:.2f}\\tAverage reward: {:.2f}\".format(\n",
    "                    i, ep_reward, running_reward\n",
    "                )\n",
    "            )\n",
    "        if running_reward > agent.env.spec.reward_threshold:\n",
    "            print(\n",
    "                \"Solved! Running reward is now {} and \".format(running_reward)\n",
    "            )\n",
    "            break\n",
    "    return running_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b248d8f-a60d-475c-8ef5-4a940f5a73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm2rewards = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b064593-f4eb-4376-9567-2a5a7d77b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm2rewards = {}\n",
    "for algorithm in ['RELAX', 'REINFORCE', 'A2C']:\n",
    "    algorithm2rewards[algorithm] = apply_benchmark(algorithm=algorithm, env_name = 'CartPole-v1', max_episode = 200, max_steps = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10df08-3f19-4fcb-94b0-2848a878d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "for algorithm in ['REINFORCE', 'A2C', 'RELAX']:\n",
    "    if algorithm in algorithm2rewards:\n",
    "        ax.plot(algorithm2rewards[algorithm], label = algorithm)\n",
    "ax.legend()\n",
    "ax.set(\n",
    "    title = 'CartPole-v1',\n",
    "    ylabel = 'reward',\n",
    "    xlabel = 'num_episides'\n",
    ")\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm2rewards = {}\n",
    "for algorithm in ['REINFORCE', 'A2C']: #'RELAX', \n",
    "    algorithm2rewards[algorithm] = apply_benchmark(algorithm=algorithm,\n",
    "                                                   env_name='Acrobot-v1',\n",
    "                                                   max_episode=200,\n",
    "                                                   max_steps = 650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5940cf83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6453103-ceb7-4f23-afce-7561875d217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "for algorithm in ['REINFORCE', 'A2C', 'RELAX']:\n",
    "    if algorithm in algorithm2rewards:\n",
    "        ax.plot(algorithm2rewards[algorithm], label = algorithm)\n",
    "ax.legend()\n",
    "ax.set(\n",
    "    title = 'Acrobot-v1',\n",
    "    ylabel = 'reward',\n",
    "    xlabel = 'num_episides'\n",
    ")\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd2fdd-49f8-4164-810e-6444793d59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm2rewards = {}\n",
    "for algorithm in ['RELAX', 'REINFORCE', 'A2C']: \n",
    "    algorithm2rewards[algorithm] = apply_benchmark(algorithm=algorithm,\n",
    "                                                   env_name='Taxi-v3',\n",
    "                                                   max_episode=200,\n",
    "                                                   max_steps = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fa508-9000-43d8-91d7-577430801769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "for algorithm in ['REINFORCE', 'A2C', 'RELAX']:\n",
    "    if algorithm in algorithm2rewards:\n",
    "        ax.plot(algorithm2rewards[algorithm], label = algorithm)\n",
    "ax.legend()\n",
    "ax.set(\n",
    "    title = 'Taxi-v3',\n",
    "    ylabel = 'reward',\n",
    "    xlabel = 'num_episides'\n",
    ")\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651f847-aa33-47ab-9137-4f411e19362d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
